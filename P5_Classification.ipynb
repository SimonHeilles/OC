{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyML4dRoQ1V4MkuQ7lOTbGQN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimonHeilles/OC/blob/main/P5_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers"
      ],
      "metadata": {
        "id": "1bD05T3q9aNf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbG5o31v5GvZ",
        "outputId": "cd4ce7d5-1c87-4d23-ca13-c3c471ccd2f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:79: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "\n",
        "#Preprocessing\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "#Train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#LDA\n",
        "import gensim.corpora as corpora\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "#Feature Extractions\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import tensorflow_hub as hub\n",
        "from transformers import (\n",
        "    DistilBertTokenizerFast,\n",
        "    TFDistilBertModel,\n",
        "    DistilBertConfig,\n",
        ")\n",
        "\n",
        "#Predictions\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Metrics\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import hamming_loss\n",
        "\n",
        "# Import\n",
        "url = 'https://raw.githubusercontent.com/SimonHeilles/OC/main/QueryResults%20(2).csv'\n",
        "data = pd.read_csv(url)\n",
        "df = data.copy()\n",
        "\n",
        "# Pre-processing\n",
        "df['Body'] = df['Body'].apply(lambda x: BeautifulSoup(x).get_text())\n",
        "\n",
        "df['Tags'] = df['Tags'].str.split().str.join(\" \")\n",
        "\n",
        "spec_chars0 = [\"<\", \">\", \"8\"]\n",
        "\n",
        "for char in spec_chars0:\n",
        "    df['Tags'] = df['Tags'].str.replace(char, ' ')\n",
        "\n",
        "df['Tags'] = df['Tags'].str.split().str.join(\" \")\n",
        "\n",
        "\n",
        "text_columns = df[['Title', 'Body']]\n",
        "\n",
        "for column in text_columns:\n",
        "  df[column] = df[column].str.lower()\n",
        "\n",
        "for column in text_columns:\n",
        "  spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
        "              \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
        "              \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
        "              \"`\",\"{\",\"|\",\"}\",\"~\",\"–\", \"$\", \"0\", \"1\",\n",
        "              \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
        "\n",
        "for char in spec_chars:\n",
        "    df[column] = df[column].str.replace(char, ' ')\n",
        "\n",
        "for column in text_columns:\n",
        "  df[column] = df[column].str.split().str.join(\" \")\n",
        "\n",
        "df2 = df.copy()\n",
        "cachedStopWords = stopwords.words(\"english\")\n",
        "\n",
        "for column in text_columns:\n",
        "  df2[column] = df2[column].apply(lambda x: [str(word) for word in word_tokenize(x) if not word in cachedStopWords])\n",
        "\n",
        "for column in text_columns:\n",
        "  df2[column] = df2[column].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# NB : no stemming, doesn't really increase the results\n",
        "\n",
        "# Preparing the list of tags\n",
        "df_cv = df2.copy()\n",
        "df_cv['TitleBody'] = df_cv['Title'] + ' ' + df_cv['Body']\n",
        "tags_list = []\n",
        "\n",
        "for words_list in df_cv['Tags']:\n",
        "  tags_list.append(words_list.split())\n",
        "\n",
        "flat_list = [item for sublist in tags_list for item in sublist]\n",
        "\n",
        "Counter = Counter(flat_list)\n",
        "\n",
        "no_words = 20 # number of words we accept in the list of tags\n",
        "\n",
        "most_occur = Counter.most_common(no_words)\n",
        "fdist=dict(zip(*np.unique(most_occur, return_counts=True)))\n",
        "list_tags = list(fdist)[-no_words:]\n",
        "\n",
        "df_cv['Tags2'] = df_cv['Tags'].apply(lambda x: [tag for tag in list_tags if tag in x.split(\" \")])\n",
        "\n",
        "index_list = []\n",
        "\n",
        "for i, row in df_cv.iterrows():\n",
        "  if len(row['Tags2']) == 0:\n",
        "    index_list.append(i) \n",
        "\n",
        "df_cv.drop(index_list, axis=0, inplace=True)\n",
        "\n",
        "X = df_cv[['TitleBody']]\n",
        "y = df_cv[['Tags2']]\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=17)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "mlb = MultiLabelBinarizer(classes=list_tags)\n",
        "y_train = mlb.fit_transform(y_train['Tags2'])\n",
        "y_test = mlb.transform(y_test['Tags2'])\n",
        "\n",
        "mlb.classes_"
      ],
      "metadata": {
        "id": "suUpifui8tIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a547e449-d224-4843-8a34-bbf7ee947cf7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['584', 'android', 'asp.net', 'c', 'c#', 'c++', 'cocoa-touch',\n",
              "       'html', 'ios', 'iphone', 'java', 'javascript', 'jquery', 'linux',\n",
              "       'objective-c', 'performance', 'php', 'python', 'sql', 'windows'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlb.classes_ = np.delete(mlb.classes_, [0])\n",
        "mlb.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sq4C7P9rIao",
        "outputId": "e5bf088d-8f3a-48db-fb98-48f383f169cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['android', 'asp.net', 'c', 'c#', 'c++', 'cocoa-touch', 'html',\n",
              "       'ios', 'iphone', 'java', 'javascript', 'jquery', 'linux',\n",
              "       'objective-c', 'performance', 'php', 'python', 'sql', 'windows'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of word"
      ],
      "metadata": {
        "id": "L9VU3Er7AFh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train0 = X_train.copy()\n",
        "X_test0 = X_test.copy()\n",
        "\n",
        "count_vect = CountVectorizer(max_features=1000, binary=True)\n",
        "\n",
        "X_train_counts = count_vect.fit_transform(X_train0['TitleBody'])\n",
        "X_test_counts = count_vect.transform(X_test0['TitleBody']) # transform seulement"
      ],
      "metadata": {
        "id": "MXY2ZDHEAFTn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Réduction dimensionnelle"
      ],
      "metadata": {
        "id": "sLJDqtP3HqOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qt = [d.split() for d in X_train0['TitleBody']]\n",
        "gensim_dictionary = corpora.Dictionary(qt)\n",
        "texts = qt\n",
        "gensim_corpus = [gensim_dictionary.doc2bow(text) for text in texts]\n",
        "print(gensim_corpus[:3])\n",
        "\n",
        "[[(gensim_dictionary[id], freq) for id, freq in cp] for cp in gensim_corpus[:4]] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvA33vulHqBh",
        "outputId": "51c0edea-4f1c-4775-9ca3-5209214e9771"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 1), (1, 2), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2), (18, 4), (19, 1), (20, 1), (21, 1), (22, 1), (23, 3), (24, 4), (25, 2), (26, 1)], [(3, 1), (27, 1), (28, 1), (29, 1), (30, 2), (31, 1), (32, 4), (33, 1), (34, 1), (35, 1), (36, 4), (37, 1), (38, 1), (39, 1), (40, 2), (41, 1), (42, 1), (43, 3), (44, 3), (45, 1), (46, 2), (47, 1), (48, 2), (49, 1), (50, 1), (51, 1), (52, 2), (53, 1), (54, 1), (55, 1), (56, 3), (57, 3), (58, 3), (59, 4), (60, 3), (61, 1), (62, 1), (63, 1), (64, 1), (65, 5), (66, 5), (67, 1), (68, 1), (69, 2), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 2), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 5), (83, 4), (84, 14), (85, 1), (86, 1), (87, 1)], [(0, 1), (3, 1), (34, 2), (70, 1), (88, 1), (89, 2), (90, 1), (91, 1), (92, 2), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 6), (102, 2), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 2), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 2), (116, 1)]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('?', 1),\n",
              "  ('assign', 2),\n",
              "  ('assigned', 2),\n",
              "  ('code', 1),\n",
              "  ('compiler', 1),\n",
              "  ('complement', 1),\n",
              "  ('could', 1),\n",
              "  ('curious', 1),\n",
              "  ('error', 1),\n",
              "  ('gets', 1),\n",
              "  ('give', 1),\n",
              "  ('happen', 1),\n",
              "  ('happens', 1),\n",
              "  ('int', 1),\n",
              "  ('know', 1),\n",
              "  ('like', 1),\n",
              "  ('look', 1),\n",
              "  ('negative', 2),\n",
              "  ('nval', 4),\n",
              "  ('program', 1),\n",
              "  ('ran', 1),\n",
              "  ('somewhat', 1),\n",
              "  ('strange', 1),\n",
              "  ('unsigned', 3),\n",
              "  ('value', 4),\n",
              "  ('variable', 2),\n",
              "  ('would', 1)],\n",
              " [('code', 1),\n",
              "  ('according', 1),\n",
              "  ('achieve', 1),\n",
              "  ('anyone', 1),\n",
              "  ('border', 2),\n",
              "  ('colored', 1),\n",
              "  ('colorize', 4),\n",
              "  ('compute', 1),\n",
              "  ('created', 1),\n",
              "  ('data', 1),\n",
              "  ('diagram', 4),\n",
              "  ('docs', 1),\n",
              "  ('e', 1),\n",
              "  ('figure', 1),\n",
              "  ('fill', 2),\n",
              "  ('forming', 1),\n",
              "  ('help', 1),\n",
              "  ('image', 3),\n",
              "  ('import', 3),\n",
              "  ('indicates', 1),\n",
              "  ('indices', 2),\n",
              "  ('ints', 1),\n",
              "  ('list', 2),\n",
              "  ('make', 1),\n",
              "  ('matplotlib', 1),\n",
              "  ('need', 1),\n",
              "  ('np', 2),\n",
              "  ('nregions', 1),\n",
              "  ('numpy', 1),\n",
              "  ('order', 1),\n",
              "  ('outside', 3),\n",
              "  ('plot', 3),\n",
              "  ('plt', 3),\n",
              "  ('points', 4),\n",
              "  ('polygon', 3),\n",
              "  ('pyplot', 1),\n",
              "  ('rand', 1),\n",
              "  ('random', 1),\n",
              "  ('reasonably', 1),\n",
              "  ('region', 5),\n",
              "  ('regions', 5),\n",
              "  ('remove', 1),\n",
              "  ('resulting', 1),\n",
              "  ('scipy', 2),\n",
              "  ('see', 1),\n",
              "  ('seem', 1),\n",
              "  ('set', 1),\n",
              "  ('shape', 1),\n",
              "  ('show', 1),\n",
              "  ('spatial', 2),\n",
              "  ('tesselation', 1),\n",
              "  ('think', 1),\n",
              "  ('tried', 1),\n",
              "  ('trying', 1),\n",
              "  ('using', 1),\n",
              "  ('vertex', 1),\n",
              "  ('vertices', 5),\n",
              "  ('vor', 4),\n",
              "  ('voronoi', 14),\n",
              "  ('well', 1),\n",
              "  ('work', 1),\n",
              "  ('zip', 1)],\n",
              " [('?', 1),\n",
              "  ('code', 1),\n",
              "  ('created', 2),\n",
              "  ('see', 1),\n",
              "  (',', 1),\n",
              "  ('`', 2),\n",
              "  ('attributes', 1),\n",
              "  ('blabla', 1),\n",
              "  ('colon', 2),\n",
              "  ('copy', 1),\n",
              "  ('directory', 1),\n",
              "  ('drives', 1),\n",
              "  ('exe', 1),\n",
              "  ('explorer', 1),\n",
              "  ('extended', 1),\n",
              "  ('file', 1),\n",
              "  ('filename', 1),\n",
              "  ('files', 6),\n",
              "  ('identifier', 2),\n",
              "  ('mean', 1),\n",
              "  ('monitor', 1),\n",
              "  ('monitoring', 1),\n",
              "  ('named', 1),\n",
              "  ('network', 1),\n",
              "  ('often', 1),\n",
              "  ('prevent', 2),\n",
              "  ('process', 1),\n",
              "  ('related', 1),\n",
              "  ('seen', 1),\n",
              "  ('windows', 1),\n",
              "  ('wsl', 1),\n",
              "  ('zone', 2),\n",
              "  ('zone.identifier', 1)],\n",
              " [('?', 1),\n",
              "  ('using', 1),\n",
              "  (\"''\", 2),\n",
              "  ('/', 1),\n",
              "  ('<', 1),\n",
              "  ('>', 1),\n",
              "  ('achieved', 1),\n",
              "  ('analytics', 1),\n",
              "  ('announced', 1),\n",
              "  ('async', 5),\n",
              "  ('async=', 1),\n",
              "  ('asynchronous', 2),\n",
              "  ('browsers', 2),\n",
              "  ('december', 1),\n",
              "  ('directive', 2),\n",
              "  ('google', 2),\n",
              "  ('script', 3),\n",
              "  ('since', 1),\n",
              "  ('support', 3),\n",
              "  ('tag', 1),\n",
              "  ('tracking', 2),\n",
              "  ('version', 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "i = 1\n",
        "\n",
        "while i < 10: #calculating and displaying the coherence score\n",
        "  lda_model = gensim.models.ldamodel.LdaModel(\n",
        "    corpus=gensim_corpus, id2word=gensim_dictionary, num_topics=i, random_state=100, \n",
        "    update_every=1, chunksize=100, passes=10, alpha='auto', per_word_topics=True\n",
        "  )\n",
        "\n",
        "  coherence_model_lda = CoherenceModel(\n",
        "    model=lda_model, texts=qt, dictionary=gensim_dictionary, coherence='c_v')\n",
        "  \n",
        "  coherence_lda = coherence_model_lda.get_coherence()\n",
        "  print('\\nCoherence Score :', coherence_lda, '// i =', i)\n",
        "  i = i + 1\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "L4GoPY5EH50j",
        "outputId": "3a7137be-a506-4632-8964-7bd405bca355"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ni = 1\\n\\nwhile i < 10: #calculating and displaying the coherence score\\n  lda_model = gensim.models.ldamodel.LdaModel(\\n    corpus=gensim_corpus, id2word=gensim_dictionary, num_topics=i, random_state=100, \\n    update_every=1, chunksize=100, passes=10, alpha='auto', per_word_topics=True\\n  )\\n\\n  coherence_model_lda = CoherenceModel(\\n    model=lda_model, texts=qt, dictionary=gensim_dictionary, coherence='c_v')\\n  \\n  coherence_lda = coherence_model_lda.get_coherence()\\n  print('\\nCoherence Score :', coherence_lda, '// i =', i)\\n  i = i + 1\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coherence Score : 0.36568419717585815 // i = 1\n",
        "\n",
        "Coherence Score : 0.3937934338982566 // i = 2\n",
        "\n",
        "Coherence Score : 0.4713507152241547 // i = 3\n",
        "\n",
        "Coherence Score : 0.48230897208942974 // i = 4\n",
        "\n",
        "Coherence Score : 0.4919717130549627 // i = 5\n",
        "\n",
        "Coherence Score : 0.47621885201636943 // i = 6\n",
        "\n",
        "Coherence Score : 0.4395823651640512 // i = 7\n",
        "\n",
        "Coherence Score : 0.5053347873156604 // i = 8\n",
        "\n",
        "Coherence Score : 0.4772248376021915 // i = 9"
      ],
      "metadata": {
        "id": "Xw5eoGYDOS24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda = LatentDirichletAllocation(\n",
        "        n_components=8, # 8 is the best feat according to the results above (highest coherence score is the 7th iteration)\n",
        "        max_iter=5, \n",
        "        learning_method='online', \n",
        "        learning_offset=50.,\n",
        "        random_state=0)\n",
        "\n",
        "lda.fit(X_train_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-W45OzDI-DU",
        "outputId": "119dd5a6-6e0f-459d-ab15-80d236a9e9cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(learning_method='online', learning_offset=50.0,\n",
              "                          max_iter=5, n_components=8, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(\"Topic {}:\".format(topic_idx))\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "        #print(topic)\n",
        "\n",
        "no_top_words = 10\n",
        "display_topics(lda, count_vect.get_feature_names_out(), no_top_words) # we can adjust the output by playing with max features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXWnwwBcJkOU",
        "outputId": "df022112-6949-426a-d49e-cf1e9d36aad7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "element function color change jquery div style elements left equal\n",
            "Topic 1:\n",
            "using like way data table would values need get value\n",
            "Topic 2:\n",
            "ios app view iphone screen image xcode bar want show\n",
            "Topic 3:\n",
            "using like way use code would get want http need\n",
            "Topic 4:\n",
            "std performance struct boost operator mean compiler high const gcc\n",
            "Topic 5:\n",
            "lang java native exception com org invoke util unknown thread\n",
            "Topic 6:\n",
            "code class return void public get new int string method\n",
            "Topic 7:\n",
            "use one using project build file need also know vs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OBSOLETE : On a du développement (web en partie avec deux langages web) avec git, et plutôt du vocabulaire avec tout ce qui concerne les bases de données."
      ],
      "metadata": {
        "id": "yRSjuAxoLj9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prédictions"
      ],
      "metadata": {
        "id": "yNDp3d8NAFFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "jscore = make_scorer(f1_score, average='micro')\n",
        "\n",
        "def preds(X_train1, X_test1, y_train1, y_test1):\n",
        "  lr_parameters = {\"estimator__C\": np.logspace(-3,3,7)}\n",
        "\n",
        "  knn_parameters = {'estimator__n_neighbors' : [3, 5, 11, 19]}\n",
        "\n",
        "  rfc_parameters = { \n",
        "      'estimator__n_estimators': [1, 5, 10],\n",
        "      'estimator__max_features': ['auto', 'log2'],\n",
        "      'estimator__max_depth' : [10, 30, 50]\n",
        "  }\n",
        "\n",
        "  lr = OneVsRestClassifier(LogisticRegression(max_iter=100))\n",
        "  lr_tuning = GridSearchCV(lr, param_grid=lr_parameters,\n",
        "                             scoring=jscore, cv=3)\n",
        "\n",
        "  lr_tuning.fit(X_train1, y_train1)\n",
        "  pred=lr_tuning.predict(X_test1)\n",
        "\n",
        "  print('\\nLogistic Regression:')\n",
        "  print(lr_tuning.best_score_)\n",
        "  print(lr_tuning.best_params_)\n",
        "  print('Jaccard score', jaccard_score(y_test1,pred, average='micro'))\n",
        "  print('Hamming loss', hamming_loss(y_test1, pred))\n",
        "  print('F1 score', f1_score(y_test1,pred, average='micro'), '\\n')\n",
        "\n",
        "  knn = OneVsRestClassifier(KNeighborsClassifier())\n",
        "  knn_tuning = GridSearchCV(knn, param_grid=knn_parameters,\n",
        "                             scoring=jscore, cv=3)\n",
        "  \n",
        "  knn_tuning.fit(X_train1, y_train1)\n",
        "  pred=knn_tuning.predict(X_test1)\n",
        "\n",
        "  print('\\nKNN:')\n",
        "  print(knn_tuning.best_score_)\n",
        "  print(knn_tuning.best_params_)\n",
        "  print('Jaccard score', jaccard_score(y_test1,pred, average='micro'))\n",
        "  print('Hamming loss', hamming_loss(y_test1, pred))\n",
        "  print('F1 score', f1_score(y_test1,pred, average='micro'), '\\n')\n",
        "\n",
        "  rfc=OneVsRestClassifier(RandomForestClassifier(random_state=42))\n",
        "  rfc_tuning = GridSearchCV(rfc, param_grid=rfc_parameters,\n",
        "                             scoring=jscore, cv=3)\n",
        "  \n",
        "  rfc_tuning.fit(X_train1, y_train1)\n",
        "  pred=rfc_tuning.predict(X_test1)\n",
        "\n",
        "  print('\\nRandom Forest Classifier:')\n",
        "  print(rfc_tuning.best_score_)\n",
        "  print(rfc_tuning.best_params_)\n",
        "  print('Jaccard score', jaccard_score(y_test1,pred, average='micro'))\n",
        "  print('Hamming loss', hamming_loss(y_test1, pred))\n",
        "  print('F1 score', f1_score(y_test1,pred, average='micro'), '\\n')\n",
        "\n",
        "#mlb.inverse_transform(pred)\n",
        "preds(X_train_counts, X_test_counts, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ4FKW45M7oD",
        "outputId": "50e4c950-0bf5-4f9b-8626-e46c7929a528"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression:\n",
            "0.5672310038290721\n",
            "{'estimator__C': 100.0}\n",
            "Jaccard score 0.41288045875606527\n",
            "Hamming loss 0.05211433046202036\n",
            "F1 score 0.5844520761785826 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "KNN:\n",
            "0.13260623086023013\n",
            "{'estimator__n_neighbors': 3}\n",
            "Jaccard score 0.08130502330398758\n",
            "Hamming loss 0.06945967110415036\n",
            "F1 score 0.1503831417624521 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 0 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Classifier:\n",
            "0.4177734881410209\n",
            "{'estimator__max_depth': 50, 'estimator__max_features': 'auto', 'estimator__n_estimators': 5}\n",
            "Jaccard score 0.2822420634920635\n",
            "Hamming loss 0.05665622552858261\n",
            "F1 score 0.44023210831721465 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6hh-EzxS7kF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec"
      ],
      "metadata": {
        "id": "S4qA8ESw5x5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train0 = X_train.copy()\n",
        "X_test0 = X_test.copy()\n",
        "\n",
        "X_train0['TitleBody'] = X_train0['TitleBody'].apply(lambda x: x.split())\n",
        "wv = Word2Vec(X_train0['TitleBody'], min_count=2)\n",
        "\n",
        "def get_vect(word, model):\n",
        "    try:\n",
        "        return model.wv[word]\n",
        "    except KeyError:\n",
        "        return np.zeros((model.vector_size,))\n",
        "\n",
        "def sum_vectors(phrase, model):\n",
        "    return sum(get_vect(w, model) for w in phrase)\n",
        "\n",
        "def word2vec_features(X, model):\n",
        "    feats = np.vstack([sum_vectors(p, model) for p in X])\n",
        "    return feats\n",
        "\n",
        "wv_train_feat = word2vec_features(X_train0[\"TitleBody\"], wv)\n",
        "wv_test_feat = word2vec_features(X_test0[\"TitleBody\"], wv)"
      ],
      "metadata": {
        "id": "ZqdzMTlI5vgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prédictions"
      ],
      "metadata": {
        "id": "-fCDLsS16MsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds(wv_train_feat, wv_test_feat, y_train, y_test)\n",
        "#mlb.inverse_transform(pred)"
      ],
      "metadata": {
        "id": "4xfAu4zr6Mac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USE"
      ],
      "metadata": {
        "id": "sVUyUBLb7_f0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train0 = X_train.copy()\n",
        "X_test0 = X_test.copy()\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "#X_train0['TitleBody'] = X_train0['TitleBody'].apply(lambda x: [x])\n",
        "\n",
        "X_train_embed = X_train0['TitleBody'].to_list()\n",
        "X_train_embed = embed(X_train_embed)\n",
        "X_train_embed = np.array(X_train_embed)\n",
        "\n",
        "X_test_embed = X_test0['TitleBody'].to_list()\n",
        "X_test_embed = embed(X_test_embed)\n",
        "X_test_embed = np.array(X_test_embed)"
      ],
      "metadata": {
        "id": "okQ21nAB6aw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prédictions"
      ],
      "metadata": {
        "id": "rhf8RQXe8X9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds(X_train_embed, X_test_embed, y_train, y_test)\n",
        "#mlb.inverse_transform(pred)"
      ],
      "metadata": {
        "id": "-9LhKxsX8ZEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT"
      ],
      "metadata": {
        "id": "dYNyk-p88bkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train0 = X_train.copy()\n",
        "X_test0 = X_test.copy()\n",
        "\n",
        "# Using DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (TFDistilBertModel, DistilBertTokenizerFast, 'distilbert-base-uncased')\n",
        "\n",
        "pretrained_bert_tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "\n",
        "def get_pretrained_bert_model(config=pretrained_weights):\n",
        "    if not config:\n",
        "        config = DistilBertConfig(num_labels=2)\n",
        "\n",
        "    return model_class.from_pretrained(pretrained_weights, config=config)\n",
        "\n",
        "def tokenize_encode(questions, max_length=None):\n",
        "    return pretrained_bert_tokenizer(\n",
        "        questions,\n",
        "        add_special_tokens=True,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"tf\",\n",
        "    )\n",
        "\n",
        "# need to be explicit about the lengths (instead of just specifying padding=True in the tokenizer)\n",
        "# otherwise train questions end up being 71 and validation questions end up as 70, which causes problems/warnings\n",
        "max_length_question = 72\n",
        "max_length_keyword = 8\n",
        "\n",
        "train_questions_encoded = tokenize_encode(X_train0[\"TitleBody\"].to_list(), max_length_question) \n",
        "validation_questions_encoded = tokenize_encode(X_test0[\"TitleBody\"].to_list(), max_length_question) \n",
        "train_inputs_encoded = dict(train_questions_encoded)\n",
        "validation_inputs_encoded = dict(validation_questions_encoded)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (dict(train_questions_encoded), y_train))\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (dict(validation_questions_encoded), y_test))\n",
        "\n",
        "train_multi_input_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_inputs_encoded, y_train))\n",
        "\n",
        "val_multi_input_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (validation_inputs_encoded, y_test))\n",
        "\n",
        "tfidf_vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(\n",
        "    min_df=1, ngram_range=(1, 1), norm=\"l2\")\n",
        "\n",
        "train_vectors = tfidf_vectorizer.fit_transform(raw_documents=X_train0[\"TitleBody\"]).toarray()\n",
        "validation_vectors = tfidf_vectorizer.transform(X_test0[\"TitleBody\"]).toarray()"
      ],
      "metadata": {
        "id": "veH0oUQc8fxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prédictions"
      ],
      "metadata": {
        "id": "U86i4B8190Xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds(train_vectors, validation_vectors, y_train, y_test)\n",
        "#mlb.inverse_transform(pred)"
      ],
      "metadata": {
        "id": "YmV6Hgf691tw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}